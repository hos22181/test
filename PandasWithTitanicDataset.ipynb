{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "In this section we examine the Pandas library for working with data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What kind of data does pandas handle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series\n",
    "A Series is a one-dimensional array-like object containing a sequence of values (of similar types to NumPy types) and an associated array of data labels, called its index.\n",
    "### Data frame\n",
    "Rectangular data (like a spreadsheet) is the basic data structure for statistical and machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age= pd.Series([41, 77, 5, 94], name = \"Age\")\n",
    "print(age)\n",
    "print(age[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concat Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([41, 77, 5, 94], name = \"Age1\")\n",
    "s2 = pd.Series([40, 70, 50, 90], name = \"Age2\")\n",
    "sconcat1 = pd.concat([s1, s2],axis=1)\n",
    "print(sconcat)\n",
    "sconcat2 = pd.concat([s1, s2],axis=0)\n",
    "print(sconcat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge() performs join operations similar to relational databases like SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [44]: left = pd.DataFrame(\n",
    "        {\n",
    "        \"key\": [\"K0\", \"K1\", \"K2\", \"K3\"],\n",
    "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "       }\n",
    "  )\n",
    "\n",
    "\n",
    "In [45]: right = pd.DataFrame(\n",
    "        {\n",
    "            \"key\": [\"K0\", \"K1\", \"K2\", \"K4\"],\n",
    "            \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "            \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
    "       }\n",
    " )\n",
    "\n",
    "\n",
    "#left join on key\n",
    "resultL = pd.merge(left, right, how=\"left\" , on=\"key\")\n",
    "print(resultL)\n",
    "#right join on key\n",
    "resultR = pd.merge(left, right, how=\"right\" , on=\"key\")\n",
    "print(resultR)\n",
    "#inner join on key\n",
    "resultI = pd.merge(left, right, how=\"inner\" , on=\"key\")\n",
    "print(resultI)\n",
    "#outer join on key\n",
    "resultO = pd.merge(left, right, how=\"outer\" , on=\"key\")\n",
    "print(resultO)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [ \n",
    "            \"Lionel Messi\",\n",
    "            \"Manuel Neuer\",\n",
    "            \"David Alaba\"      \n",
    "        ], \n",
    "        \"age\": [36,37,31],\n",
    "        \"sex\": [\"m\",\"m\",\"m\"]\n",
    "    } );\n",
    "        \n",
    "print(df)\n",
    "df\n",
    "\n",
    "# Data frame has always an index \n",
    "df.index\n",
    "print(\"df.index: \", df.index)\n",
    "\n",
    "# Also a \"named\" index (like a PK)\n",
    "\n",
    "df.index = [\"lm\",\"mn\",\"da\"]\n",
    "print(\"\\n df with new index \\n\", df)\n",
    "\n",
    "# With loc[] -> search index\n",
    "df.loc[\"lm\"] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data frames from Lists and Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two lists\n",
    "author = ['Goedel', 'Turing', 'McCarthy', 'Minsky']\n",
    "article = [210, 211, 114, 178]\n",
    "\n",
    "# Convert article to DataFrame\n",
    "articledf = pd.DataFrame(article, columns=['Numbers'])\n",
    "print(articledf.head())\n",
    " \n",
    "# Creating two Series by passing lists\n",
    "auth_series = pd.Series(author)\n",
    "article_series = pd.Series(article)\n",
    " \n",
    "# Creating a dictionary by passing Series objects as values\n",
    "frame = {'Author': auth_series,\n",
    "         'Article': article_series}\n",
    " \n",
    "# Creating DataFrame by passing Dictionary\n",
    "result = pd.DataFrame(frame)\n",
    " \n",
    "# Printing elements of Dataframe\n",
    "print(result)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Infos about Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "age= pd.Series([41, 77, 5, 94], name = \"Age\")\n",
    "print(age)\n",
    "print(age[0:2])\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [ \n",
    "            \"Lionel Messi\",\n",
    "            \"Manuel Neuer\",\n",
    "            \"David Alaba\"      \n",
    "        ], \n",
    "        \"age\": [36,37,31],\n",
    "        \"sex\": [\"m\",\"m\",\"m\"]\n",
    "    } );\n",
    "        \n",
    "print(df)\n",
    "df\n",
    "\n",
    "# Data frame has always an index \n",
    "df.index\n",
    "\n",
    "# Also a \"named\" index (like a PK)\n",
    "\n",
    "df.index = [\"lm\",\"mn\",\"da\"]\n",
    "\n",
    "# With loc[] -> search index\n",
    "df.loc[\"lm\"] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc[] is used to access elements of a Series/DataFrame by using the index of the elements.\n",
    "my_series = pd.Series([10,20,30,40,50])\n",
    "print(my_series.iloc[2])  # access the 3rd element of the series\n",
    "\n",
    "# iloc[] can be used to access elements of a DataFrame\n",
    "print(df.iloc[1,1])  # access the element in the 2nd row and 2nd column\n",
    "\n",
    "print(df.loc[\"mn\",\"age\"])  # access the element in the row with index \"mn\" and column \"age\"\n",
    "\n",
    "df.iloc[1,1] = 100  # change the value of the element in the 2nd row and 2nd column\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL like queries with pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': [1,2,3,4], 'B': [5,6,7,8]})\n",
    "\n",
    "df[\"A\"] >  2 # returns a boolean series\n",
    "df[(df[\"A\"] > 2) & (df[\"B\"]> 7)]  # returns a DataFrame\n",
    "\n",
    "df2 = pd.DataFrame({'Name': ['John', 'Paul', 'George', 'Ingo'], 'Age': [22, 21, 20, 24]})\n",
    "\n",
    "df2['Age'].mean()  # calculate the mean of the column 'Age'\n",
    "df2[(df2['Age'] > 20) & (df2['Age'] < 23)]  # select rows where the age is between 20 and 23\n",
    "\n",
    "df2[(df2['Name'] > \"George\") & (df2['Age'] < 28)]   # SQL like query with pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Import CSV and Part of CSV into Dataframe\n",
    "\n",
    "Importing csv files can be done by using the pandas method read_csv() \n",
    "\n",
    "In some cases, you might want to read only a specific part of a large dataset to save memory or to focus on a particular subset of the data. This can be done using the `usecols` parameter in the `read_csv` function to specify which columns to read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homedir = \"C:/Home/DSAI/datasets/titanic.csv\"\n",
    "titanicdf = pd.read_csv(homedir, sep=';', decimal = ',',skiprows=[1])  # skip the first row\n",
    "\n",
    "# overview of the data\n",
    "titanicdf.head()\n",
    "titanicdf.describe()  \n",
    "titanicdf.info()\n",
    "\n",
    "# Selecting columns and rows\n",
    "#titanicdf1 = pd.read_csv(homedir, sep=';', header=0, usecols=[\"name\", \"sex\", \"age\"]\n",
    "                     #  , index_col=[\"age\",\"name\"] # new order of columns and index, nrows=5 # number of rows to read)\n",
    "\n",
    "# Export to csv\n",
    "#titanicdf.to_csv('titanicdf.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home destinations of passengers from New York\n",
    "titanicdf[titanicdf[\"home.dest\"] == \"New York, NY\"]\n",
    "titanicdf[titanicdf[\"home.dest\"] == \"New York, NY\"].shape[0]  # length of the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list unique values of a column\n",
    "print(titanicdf['home.dest'].value_counts())\n",
    "\n",
    "# list home destinations\n",
    "my_list = list(titanicdf['home.dest'].unique())\n",
    "print(my_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanicdf[\"survived\"].value_counts()  # count the number of passengers who survived [1] and who did not survive [0]\n",
    "\n",
    "titanicdf[\"survived\"].value_counts(normalize=True)  # percentage of passengers who survived and who did not survive \n",
    "\n",
    "notsurvived  = titanicdf[\"survived\"].value_counts(normalize=True)[0]   # = titanicdf[titanicdf[\"survived\"] == 0]\n",
    "survived  = titanicdf[\"survived\"].value_counts(normalize=True)[1]   # = titanicdf[titanicdf[\"survived\"] == 1]\n",
    "\n",
    "print(\"Not survived: \", round(notsurvived,3))\n",
    "print(\"survived: \", round(survived,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "titanicdf.isna().sum()  # count the number of missing values in each column\n",
    "\n",
    "titanicdf[\"cabin\"].isna().sum()  # count the number of missing values in the column 'cabin' -  most of the values are missin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check if the missing values for embark and homedst column are for the same person,\n",
    "# otherwise both columns could be filled based on the other column's value\n",
    "df = titanicdf\n",
    "df['embarked'][(df['embarked'].isnull()) & (df['home.dest'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of female/male passengers\n",
    "female = titanicdf[ titanicdf[\"sex\"] == \"female\"].shape[0]  # number\n",
    "male = titanicdf[ titanicdf[\"sex\"] == \"male\"].shape[0]  # number\n",
    "print(\"Number of female passengers: \", female,\"\\n\", \"Number of male passengers\",male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survival Rate/Sex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanicdf[(titanicdf[\"sex\"] == \"male\") & (titanicdf[\"survived\"] == 1)][\"PassengerId\"].count()   # number of survived males \n",
    "titanicdf[(titanicdf[\"sex\"] == \"female\") & (titanicdf[\"survived\"] == 1)][\"PassengerId\"].count()   # number of survived females \n",
    "\n",
    "titanicdf[(titanicdf[\"sex\"] == \"male\") & (titanicdf[\"survived\"] == 0)][\"PassengerId\"].count()   # number of not survived males \n",
    "titanicdf[(titanicdf[\"sex\"] == \"female\") & (titanicdf[\"survived\"] == 0)][\"PassengerId\"].count()   # number of not survived females \n",
    "\n",
    "#titanicdf.groupby(\"sex\")[\"survived\"==1].count()\n",
    "#titanicdf.groupby(\"sex\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# rename the column pclass to class\n",
    "titanicdf.rename(columns={\"pclass\": \"class\"}, inplace=True)\n",
    "\n",
    "# find each class's highest fare\n",
    "print(titanicdf.groupby('class')['fare'].max())\n",
    "# mean age of each class\n",
    "titanicdf.groupby('class')['age'].mean()\n",
    "\n",
    "# Grouping data by survival status and gender\n",
    "# grouped_data = titanicdf.groupby(['survived', 'sex'])[\"PassengerId\"].count() # count the number of passengers in each group show only one column\n",
    "\n",
    "# better to use size() instead of count() to get the total number of passengers in each group\n",
    "#grouped_data = titanicdf.groupby(['survived', 'sex']).size()\n",
    "\n",
    "# unstack() is used to reshape the data\n",
    "grouped_data = titanicdf.groupby(['survived', 'sex']).size().unstack()\n",
    "\n",
    "#select the number female passengers who survived\n",
    "#grouped_data = titanicdf.groupby(['survived', 'sex']).size().unstack().iloc[1,0]\n",
    "\n",
    "# Display the grouped data\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean age of passengers who survived and who did not survive\n",
    "titanicdf.groupby(\"survived\")[\"age\"].mean(\"age\")\n",
    "\n",
    "# Mean age of passengers depending on the cabin\n",
    "titanicdf.groupby(\"cabin\")[\"age\"].mean(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival rate depending on the cabin class\n",
    "survived = titanicdf[[\"class\", \"survived\"]].groupby(\"class\").sum()\n",
    "all = titanicdf[[\"class\", \"survived\"]].groupby(\"class\").count()\n",
    "dead = all - survived\n",
    "print(all,survived,dead, survived*100/all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set missing age values to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Age\"].groupby(df2[\"Age\"]).count()\n",
    "df2[\"Age\"].fillna(-1, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passengers with the same ticket number (= familiy ?)\n",
    "titanicdf[\"ticket\"].groupby(titanicdf[\"ticket\"]).count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check if families survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanicdf[titanicdf[\"ticket\"] == \"1601\"][[\"ticket\",\"name\",\"survived\",\"age\"]]\n",
    "\n",
    "titanicdf[titanicdf[\"ticket\"].isin([\"CA. 2343\",\"1601\",\"CA 2144\",\"3101295\"])][[\"ticket\",\"name\",\"survived\",\"age\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Adding a new row to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data to be inserted\n",
    "new_data = {\n",
    "    'PassengerId': 1311,\n",
    "    'survived': 1,\n",
    "    'pclass': 1,\n",
    "    'name': 'Doe, Mr. John',\n",
    "    'sex': 'male',\n",
    "    'age': 30,\n",
    "    'sibsp': 0,\n",
    "    'parch': 0,\n",
    "    'ticket': '12345',\n",
    "    'fare': '100.00',\n",
    "    'cabin': 'C123',\n",
    "    'embarked': 'S',\n",
    "    'boat': '2',\n",
    "    'body': None,\n",
    "    'homedest': 'New York, NY',\n",
    "    'pclassint': 1,\n",
    "    'age_category': 'Adult'\n",
    "}\n",
    "\n",
    "newdf = pd.DataFrame(new_data, index=[0])\n",
    "\n",
    "newdf.head()\n",
    "\n",
    "# titanicdf = titanicdf.append(new_data, ignore_index = True)   -> removed pandas 2.0\n",
    "titanicdf = pd.concat([titanicdf, newdf], ignore_index = True) \n",
    " \n",
    "# Display the last few rows to verify the insertion\n",
    "print(titanicdf.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat() DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a DataFrame with passengers only from London and Paris\n",
    "\n",
    "df_london = titanicdf[titanicdf['home.dest'] == \"London\"]  # select passengers from London\n",
    "df_paris = titanicdf[titanicdf['home.dest'] == \"Paris\"]  # select passengers from Paris\n",
    "\n",
    "# Concatenate the extracted rows into a new DataFrame\n",
    "df_londonparis = pd.concat([df_london,df_paris], ignore_index=True, axis=0) # axis {0/’index’, 1/’columns’}, default 0\n",
    "                                                                            # ignore_index bool, default False I\n",
    "                                                                            # f True, do not use the index values along the concatenation axis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nice output with display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set options for the display\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 2)\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "\n",
    "display(df_londonparis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pandas Cut – Continuous to Categorical\n",
    "\n",
    "* Sometimes analysis becomes effortless on conversion from continuous to discrete data. \n",
    "* Pandas’ cut function is a distinguished way of converting numerical continuous data into categorical data. It has 3 major  necessary parts:\n",
    "    * First and foremost is the 1-D array/DataFrame required for input.\n",
    "    * Bins represent boundaries of separate bins for continuous data. bins = 0,10,20, ... -> (0-10], (10-20] , etc \n",
    "    * Labels: The number of labels without exception will be one lower than the number of bins. [\"young\", \"middle\", ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanicdf['c_class'] = pd.cut(x=titanicdf['class'], bins=[0, 1, 2, 4],\n",
    "                     labels=['1st_class', '2d_class', '3rd_class'])\n",
    "\n",
    "titanicdf[\"c_class\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
